{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13260730,"sourceType":"datasetVersion","datasetId":8403108}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MLP Project – Predicting Purchase Value from Session Data","metadata":{}},{"cell_type":"markdown","source":"##### Importing basic libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport warnings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:19:38.384112Z","iopub.execute_input":"2025-10-04T14:19:38.384449Z","iopub.status.idle":"2025-10-04T14:19:38.389143Z","shell.execute_reply.started":"2025-10-04T14:19:38.384424Z","shell.execute_reply":"2025-10-04T14:19:38.388134Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# Importing the training and testing dataset into df and dft\ndf = pd.read_csv('/kaggle/input/e-commerce-dataset/train_data.csv')\ndft = pd.read_csv('/kaggle/input/e-commerce-dataset/test_data.csv')\n\n# Setting option to display all the columns\npd.set_option('display.max_columns', None)\n\n# To avoid warnings\nwarnings.filterwarnings(\"ignore\")\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:19:38.579756Z","iopub.execute_input":"2025-10-04T14:19:38.580634Z","iopub.status.idle":"2025-10-04T14:19:41.190328Z","shell.execute_reply.started":"2025-10-04T14:19:38.580605Z","shell.execute_reply":"2025-10-04T14:19:41.189518Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"       trafficSource.isTrueDirect  purchaseValue            browser  \\\n0                             NaN            0.0               Edge   \n1                            True            0.0             Chrome   \n2                            True            0.0             Chrome   \n3                             NaN            0.0  Internet Explorer   \n4                            True     88950000.0             Chrome   \n...                           ...            ...                ...   \n116018                        NaN     35180000.0             Chrome   \n116019                       True            0.0             Chrome   \n116020                       True            0.0             Chrome   \n116021                        NaN            0.0             Chrome   \n116022                       True     81470000.0             Chrome   \n\n              device.screenResolution trafficSource.adContent  \\\n0       not available in demo dataset                     NaN   \n1       not available in demo dataset                     NaN   \n2       not available in demo dataset                     NaN   \n3       not available in demo dataset                     NaN   \n4       not available in demo dataset                     NaN   \n...                               ...                     ...   \n116018  not available in demo dataset                     NaN   \n116019  not available in demo dataset                     NaN   \n116020  not available in demo dataset                     NaN   \n116021  not available in demo dataset                     NaN   \n116022  not available in demo dataset                     NaN   \n\n       trafficSource.keyword screenSize geoCluster  \\\n0                        NaN     medium   Region_2   \n1                        NaN     medium   Region_3   \n2             (not provided)     medium   Region_2   \n3                        NaN     medium   Region_4   \n4                        NaN     medium   Region_3   \n...                      ...        ...        ...   \n116018                   NaN     medium   Region_3   \n116019                   NaN     medium   Region_5   \n116020                   NaN     medium   Region_1   \n116021        (not provided)     medium   Region_5   \n116022        (not provided)     medium   Region_5   \n\n       trafficSource.adwordsClickInfo.slot    device.mobileDeviceBranding  \\\n0                                      NaN  not available in demo dataset   \n1                                      NaN  not available in demo dataset   \n2                                      NaN  not available in demo dataset   \n3                                      NaN  not available in demo dataset   \n4                                      NaN  not available in demo dataset   \n...                                    ...                            ...   \n116018                                 NaN  not available in demo dataset   \n116019                                 NaN  not available in demo dataset   \n116020                                 NaN  not available in demo dataset   \n116021                                 NaN  not available in demo dataset   \n116022                                 NaN  not available in demo dataset   \n\n           device.mobileInputSelector  userId trafficSource.campaign  \\\n0       not available in demo dataset   61421              (not set)   \n1       not available in demo dataset   72287              (not set)   \n2       not available in demo dataset   25180              (not set)   \n3       not available in demo dataset   41295              (not set)   \n4       not available in demo dataset  113697              (not set)   \n...                               ...     ...                    ...   \n116018  not available in demo dataset  109014              (not set)   \n116019  not available in demo dataset   66111              (not set)   \n116020  not available in demo dataset   97614              (not set)   \n116021  not available in demo dataset   71050              (not set)   \n116022  not available in demo dataset   39773              (not set)   \n\n       device.mobileDeviceMarketingName geoNetwork.networkDomain  \\\n0         not available in demo dataset                  domain1   \n1         not available in demo dataset                  domain3   \n2         not available in demo dataset                  domain1   \n3         not available in demo dataset                  domain3   \n4         not available in demo dataset                  domain1   \n...                                 ...                      ...   \n116018    not available in demo dataset                  domain1   \n116019    not available in demo dataset                  domain2   \n116020    not available in demo dataset                  domain2   \n116021    not available in demo dataset                  domain1   \n116022    not available in demo dataset                  domain2   \n\n        gclIdPresent  device.operatingSystemVersion  sessionNumber  \\\n0                  0  not available in demo dataset              1   \n1                  0  not available in demo dataset              1   \n2                  0  not available in demo dataset              2   \n3                  0  not available in demo dataset              1   \n4                  0  not available in demo dataset              1   \n...              ...                            ...            ...   \n116018             0  not available in demo dataset              1   \n116019             0  not available in demo dataset              1   \n116020             0  not available in demo dataset              2   \n116021             0  not available in demo dataset              1   \n116022             0  not available in demo dataset              4   \n\n                  device.flashVersion              geoNetwork.region  \\\n0       not available in demo dataset                     Washington   \n1       not available in demo dataset                     California   \n2       not available in demo dataset                       Lombardy   \n3       not available in demo dataset  not available in demo dataset   \n4       not available in demo dataset  not available in demo dataset   \n...                               ...                            ...   \n116018  not available in demo dataset                       New York   \n116019  not available in demo dataset                     California   \n116020  not available in demo dataset                          Delhi   \n116021  not available in demo dataset                      Tennessee   \n116022  not available in demo dataset  not available in demo dataset   \n\n           trafficSource  totals.visits     geoNetwork.networkLocation  \\\n0            youtube.com              1  not available in demo dataset   \n1               (direct)              1  not available in demo dataset   \n2                 google              1  not available in demo dataset   \n3            youtube.com              1  not available in demo dataset   \n4               (direct)              1  not available in demo dataset   \n...                  ...            ...                            ...   \n116018          (direct)              1  not available in demo dataset   \n116019          (direct)              1  not available in demo dataset   \n116020  seroundtable.com              1  not available in demo dataset   \n116021            google              1  not available in demo dataset   \n116022            google              1  not available in demo dataset   \n\n         sessionId         os geoNetwork.subContinent trafficSource.medium  \\\n0       1500100799    Windows        Northern America             referral   \n1       1495262065  Macintosh        Northern America               (none)   \n2       1508510328    Windows         Southern Europe              organic   \n3       1483431838    Windows            Eastern Asia             referral   \n4       1475804633    Windows        Northern America               (none)   \n...            ...        ...                     ...                  ...   \n116018  1500318402  Macintosh        Northern America               (none)   \n116019  1478624150  Macintosh        Northern America               (none)   \n116020  1470384216    Windows           Southern Asia             referral   \n116021  1506953297    Windows        Northern America              organic   \n116022  1501474532    Android        Northern America              organic   \n\n       trafficSource.adwordsClickInfo.isVideoAd  \\\n0                                           NaN   \n1                                           NaN   \n2                                           NaN   \n3                                           NaN   \n4                                           NaN   \n...                                         ...   \n116018                                      NaN   \n116019                                      NaN   \n116020                                      NaN   \n116021                                      NaN   \n116022                                      NaN   \n\n                         browserMajor locationCountry  \\\n0       not available in demo dataset   United States   \n1       not available in demo dataset   United States   \n2       not available in demo dataset           Italy   \n3       not available in demo dataset           Japan   \n4       not available in demo dataset   United States   \n...                               ...             ...   \n116018  not available in demo dataset   United States   \n116019  not available in demo dataset   United States   \n116020  not available in demo dataset           India   \n116021  not available in demo dataset   United States   \n116022  not available in demo dataset          Canada   \n\n                   device.browserSize  \\\n0       not available in demo dataset   \n1       not available in demo dataset   \n2       not available in demo dataset   \n3       not available in demo dataset   \n4       not available in demo dataset   \n...                               ...   \n116018  not available in demo dataset   \n116019  not available in demo dataset   \n116020  not available in demo dataset   \n116021  not available in demo dataset   \n116022  not available in demo dataset   \n\n       trafficSource.adwordsClickInfo.adNetworkType  socialEngagementType  \\\n0                                               NaN  Not Socially Engaged   \n1                                               NaN  Not Socially Engaged   \n2                                               NaN  Not Socially Engaged   \n3                                               NaN  Not Socially Engaged   \n4                                               NaN  Not Socially Engaged   \n...                                             ...                   ...   \n116018                                          NaN  Not Socially Engaged   \n116019                                          NaN  Not Socially Engaged   \n116020                                          NaN  Not Socially Engaged   \n116021                                          NaN  Not Socially Engaged   \n116022                                          NaN  Not Socially Engaged   \n\n                      geoNetwork.city  trafficSource.adwordsClickInfo.page  \\\n0                             Redmond                                  NaN   \n1                       Mountain View                                  NaN   \n2                               Milan                                  NaN   \n3       not available in demo dataset                                  NaN   \n4       not available in demo dataset                                  NaN   \n...                               ...                                  ...   \n116018                       New York                                  NaN   \n116019                  Mountain View                                  NaN   \n116020                      New Delhi                                  NaN   \n116021                      Nashville                                  NaN   \n116022  not available in demo dataset                                  NaN   \n\n                         geoNetwork.metro  pageViews  locationZone  \\\n0                       Seattle-Tacoma WA        1.0             8   \n1       San Francisco-Oakland-San Jose CA        1.0             8   \n2                               (not set)        6.0             8   \n3           not available in demo dataset        1.0             8   \n4           not available in demo dataset       54.0             8   \n...                                   ...        ...           ...   \n116018                        New York NY       26.0             8   \n116019  San Francisco-Oakland-San Jose CA        1.0             8   \n116020                          (not set)        1.0             8   \n116021                       Nashville TN        2.0             8   \n116022      not available in demo dataset       73.0             8   \n\n             device.mobileDeviceModel  \\\n0       not available in demo dataset   \n1       not available in demo dataset   \n2       not available in demo dataset   \n3       not available in demo dataset   \n4       not available in demo dataset   \n...                               ...   \n116018  not available in demo dataset   \n116019  not available in demo dataset   \n116020  not available in demo dataset   \n116021  not available in demo dataset   \n116022  not available in demo dataset   \n\n                               trafficSource.referralPath  totals.bounces  \\\n0                                      /intl/hr/yt/about/             1.0   \n1                                                     NaN             1.0   \n2                                                     NaN             NaN   \n3                                           /yt/about/ja/             1.0   \n4                                                     NaN             NaN   \n...                                                   ...             ...   \n116018                                                  /             NaN   \n116019                                                NaN             1.0   \n116020  /google-analytics-launches-public-demo-account...             1.0   \n116021                                                NaN             NaN   \n116022                                                NaN             NaN   \n\n            date                device.language deviceType     userChannel  \\\n0       20170714  not available in demo dataset    desktop          Social   \n1       20170519  not available in demo dataset    desktop          Direct   \n2       20171020  not available in demo dataset    desktop  Organic Search   \n3       20170103  not available in demo dataset    desktop          Social   \n4       20161006  not available in demo dataset    desktop          Direct   \n...          ...                            ...        ...             ...   \n116018  20170717  not available in demo dataset    desktop        Referral   \n116019  20161108  not available in demo dataset    desktop          Direct   \n116020  20160805  not available in demo dataset    desktop        Referral   \n116021  20171002  not available in demo dataset    desktop  Organic Search   \n116022  20170730  not available in demo dataset     mobile  Organic Search   \n\n                device.browserVersion  totalHits  \\\n0       not available in demo dataset          1   \n1       not available in demo dataset          1   \n2       not available in demo dataset          6   \n3       not available in demo dataset          1   \n4       not available in demo dataset         66   \n...                               ...        ...   \n116018  not available in demo dataset         28   \n116019  not available in demo dataset          1   \n116020  not available in demo dataset          1   \n116021  not available in demo dataset          2   \n116022  not available in demo dataset        102   \n\n                  device.screenColors  sessionStart geoNetwork.continent  \\\n0       not available in demo dataset    1500100799             Americas   \n1       not available in demo dataset    1495262065             Americas   \n2       not available in demo dataset    1508510328               Europe   \n3       not available in demo dataset    1483431838                 Asia   \n4       not available in demo dataset    1475804633             Americas   \n...                               ...           ...                  ...   \n116018  not available in demo dataset    1500318402             Americas   \n116019  not available in demo dataset    1478624150             Americas   \n116020  not available in demo dataset    1470384216                 Asia   \n116021  not available in demo dataset    1506953297             Americas   \n116022  not available in demo dataset    1501474532             Americas   \n\n        device.isMobile  new_visits  \n0                 False         1.0  \n1                 False         1.0  \n2                 False         NaN  \n3                 False         1.0  \n4                 False         1.0  \n...                 ...         ...  \n116018            False         1.0  \n116019            False         1.0  \n116020            False         NaN  \n116021            False         1.0  \n116022             True         NaN  \n\n[116023 rows x 52 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>trafficSource.isTrueDirect</th>\n      <th>purchaseValue</th>\n      <th>browser</th>\n      <th>device.screenResolution</th>\n      <th>trafficSource.adContent</th>\n      <th>trafficSource.keyword</th>\n      <th>screenSize</th>\n      <th>geoCluster</th>\n      <th>trafficSource.adwordsClickInfo.slot</th>\n      <th>device.mobileDeviceBranding</th>\n      <th>device.mobileInputSelector</th>\n      <th>userId</th>\n      <th>trafficSource.campaign</th>\n      <th>device.mobileDeviceMarketingName</th>\n      <th>geoNetwork.networkDomain</th>\n      <th>gclIdPresent</th>\n      <th>device.operatingSystemVersion</th>\n      <th>sessionNumber</th>\n      <th>device.flashVersion</th>\n      <th>geoNetwork.region</th>\n      <th>trafficSource</th>\n      <th>totals.visits</th>\n      <th>geoNetwork.networkLocation</th>\n      <th>sessionId</th>\n      <th>os</th>\n      <th>geoNetwork.subContinent</th>\n      <th>trafficSource.medium</th>\n      <th>trafficSource.adwordsClickInfo.isVideoAd</th>\n      <th>browserMajor</th>\n      <th>locationCountry</th>\n      <th>device.browserSize</th>\n      <th>trafficSource.adwordsClickInfo.adNetworkType</th>\n      <th>socialEngagementType</th>\n      <th>geoNetwork.city</th>\n      <th>trafficSource.adwordsClickInfo.page</th>\n      <th>geoNetwork.metro</th>\n      <th>pageViews</th>\n      <th>locationZone</th>\n      <th>device.mobileDeviceModel</th>\n      <th>trafficSource.referralPath</th>\n      <th>totals.bounces</th>\n      <th>date</th>\n      <th>device.language</th>\n      <th>deviceType</th>\n      <th>userChannel</th>\n      <th>device.browserVersion</th>\n      <th>totalHits</th>\n      <th>device.screenColors</th>\n      <th>sessionStart</th>\n      <th>geoNetwork.continent</th>\n      <th>device.isMobile</th>\n      <th>new_visits</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Edge</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>medium</td>\n      <td>Region_2</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>61421</td>\n      <td>(not set)</td>\n      <td>not available in demo dataset</td>\n      <td>domain1</td>\n      <td>0</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>Washington</td>\n      <td>youtube.com</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1500100799</td>\n      <td>Windows</td>\n      <td>Northern America</td>\n      <td>referral</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>United States</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>Not Socially Engaged</td>\n      <td>Redmond</td>\n      <td>NaN</td>\n      <td>Seattle-Tacoma WA</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>not available in demo dataset</td>\n      <td>/intl/hr/yt/about/</td>\n      <td>1.0</td>\n      <td>20170714</td>\n      <td>not available in demo dataset</td>\n      <td>desktop</td>\n      <td>Social</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1500100799</td>\n      <td>Americas</td>\n      <td>False</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>Chrome</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>medium</td>\n      <td>Region_3</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>72287</td>\n      <td>(not set)</td>\n      <td>not available in demo dataset</td>\n      <td>domain3</td>\n      <td>0</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>California</td>\n      <td>(direct)</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1495262065</td>\n      <td>Macintosh</td>\n      <td>Northern America</td>\n      <td>(none)</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>United States</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>Not Socially Engaged</td>\n      <td>Mountain View</td>\n      <td>NaN</td>\n      <td>San Francisco-Oakland-San Jose CA</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>20170519</td>\n      <td>not available in demo dataset</td>\n      <td>desktop</td>\n      <td>Direct</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1495262065</td>\n      <td>Americas</td>\n      <td>False</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>Chrome</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>(not provided)</td>\n      <td>medium</td>\n      <td>Region_2</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>25180</td>\n      <td>(not set)</td>\n      <td>not available in demo dataset</td>\n      <td>domain1</td>\n      <td>0</td>\n      <td>not available in demo dataset</td>\n      <td>2</td>\n      <td>not available in demo dataset</td>\n      <td>Lombardy</td>\n      <td>google</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1508510328</td>\n      <td>Windows</td>\n      <td>Southern Europe</td>\n      <td>organic</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>Italy</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>Not Socially Engaged</td>\n      <td>Milan</td>\n      <td>NaN</td>\n      <td>(not set)</td>\n      <td>6.0</td>\n      <td>8</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20171020</td>\n      <td>not available in demo dataset</td>\n      <td>desktop</td>\n      <td>Organic Search</td>\n      <td>not available in demo dataset</td>\n      <td>6</td>\n      <td>not available in demo dataset</td>\n      <td>1508510328</td>\n      <td>Europe</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Internet Explorer</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>medium</td>\n      <td>Region_4</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>41295</td>\n      <td>(not set)</td>\n      <td>not available in demo dataset</td>\n      <td>domain3</td>\n      <td>0</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>youtube.com</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1483431838</td>\n      <td>Windows</td>\n      <td>Eastern Asia</td>\n      <td>referral</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>Japan</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>Not Socially Engaged</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>not available in demo dataset</td>\n      <td>/yt/about/ja/</td>\n      <td>1.0</td>\n      <td>20170103</td>\n      <td>not available in demo dataset</td>\n      <td>desktop</td>\n      <td>Social</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1483431838</td>\n      <td>Asia</td>\n      <td>False</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>True</td>\n      <td>88950000.0</td>\n      <td>Chrome</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>medium</td>\n      <td>Region_3</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>113697</td>\n      <td>(not set)</td>\n      <td>not available in demo dataset</td>\n      <td>domain1</td>\n      <td>0</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>(direct)</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1475804633</td>\n      <td>Windows</td>\n      <td>Northern America</td>\n      <td>(none)</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>United States</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>Not Socially Engaged</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>54.0</td>\n      <td>8</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20161006</td>\n      <td>not available in demo dataset</td>\n      <td>desktop</td>\n      <td>Direct</td>\n      <td>not available in demo dataset</td>\n      <td>66</td>\n      <td>not available in demo dataset</td>\n      <td>1475804633</td>\n      <td>Americas</td>\n      <td>False</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>116018</th>\n      <td>NaN</td>\n      <td>35180000.0</td>\n      <td>Chrome</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>medium</td>\n      <td>Region_3</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>109014</td>\n      <td>(not set)</td>\n      <td>not available in demo dataset</td>\n      <td>domain1</td>\n      <td>0</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>New York</td>\n      <td>(direct)</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1500318402</td>\n      <td>Macintosh</td>\n      <td>Northern America</td>\n      <td>(none)</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>United States</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>Not Socially Engaged</td>\n      <td>New York</td>\n      <td>NaN</td>\n      <td>New York NY</td>\n      <td>26.0</td>\n      <td>8</td>\n      <td>not available in demo dataset</td>\n      <td>/</td>\n      <td>NaN</td>\n      <td>20170717</td>\n      <td>not available in demo dataset</td>\n      <td>desktop</td>\n      <td>Referral</td>\n      <td>not available in demo dataset</td>\n      <td>28</td>\n      <td>not available in demo dataset</td>\n      <td>1500318402</td>\n      <td>Americas</td>\n      <td>False</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>116019</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>Chrome</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>medium</td>\n      <td>Region_5</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>66111</td>\n      <td>(not set)</td>\n      <td>not available in demo dataset</td>\n      <td>domain2</td>\n      <td>0</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>California</td>\n      <td>(direct)</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1478624150</td>\n      <td>Macintosh</td>\n      <td>Northern America</td>\n      <td>(none)</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>United States</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>Not Socially Engaged</td>\n      <td>Mountain View</td>\n      <td>NaN</td>\n      <td>San Francisco-Oakland-San Jose CA</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>20161108</td>\n      <td>not available in demo dataset</td>\n      <td>desktop</td>\n      <td>Direct</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1478624150</td>\n      <td>Americas</td>\n      <td>False</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>116020</th>\n      <td>True</td>\n      <td>0.0</td>\n      <td>Chrome</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>medium</td>\n      <td>Region_1</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>97614</td>\n      <td>(not set)</td>\n      <td>not available in demo dataset</td>\n      <td>domain2</td>\n      <td>0</td>\n      <td>not available in demo dataset</td>\n      <td>2</td>\n      <td>not available in demo dataset</td>\n      <td>Delhi</td>\n      <td>seroundtable.com</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1470384216</td>\n      <td>Windows</td>\n      <td>Southern Asia</td>\n      <td>referral</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>India</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>Not Socially Engaged</td>\n      <td>New Delhi</td>\n      <td>NaN</td>\n      <td>(not set)</td>\n      <td>1.0</td>\n      <td>8</td>\n      <td>not available in demo dataset</td>\n      <td>/google-analytics-launches-public-demo-account...</td>\n      <td>1.0</td>\n      <td>20160805</td>\n      <td>not available in demo dataset</td>\n      <td>desktop</td>\n      <td>Referral</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1470384216</td>\n      <td>Asia</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>116021</th>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>Chrome</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>(not provided)</td>\n      <td>medium</td>\n      <td>Region_5</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>71050</td>\n      <td>(not set)</td>\n      <td>not available in demo dataset</td>\n      <td>domain1</td>\n      <td>0</td>\n      <td>not available in demo dataset</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>Tennessee</td>\n      <td>google</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1506953297</td>\n      <td>Windows</td>\n      <td>Northern America</td>\n      <td>organic</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>United States</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>Not Socially Engaged</td>\n      <td>Nashville</td>\n      <td>NaN</td>\n      <td>Nashville TN</td>\n      <td>2.0</td>\n      <td>8</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20171002</td>\n      <td>not available in demo dataset</td>\n      <td>desktop</td>\n      <td>Organic Search</td>\n      <td>not available in demo dataset</td>\n      <td>2</td>\n      <td>not available in demo dataset</td>\n      <td>1506953297</td>\n      <td>Americas</td>\n      <td>False</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>116022</th>\n      <td>True</td>\n      <td>81470000.0</td>\n      <td>Chrome</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>(not provided)</td>\n      <td>medium</td>\n      <td>Region_5</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>39773</td>\n      <td>(not set)</td>\n      <td>not available in demo dataset</td>\n      <td>domain2</td>\n      <td>0</td>\n      <td>not available in demo dataset</td>\n      <td>4</td>\n      <td>not available in demo dataset</td>\n      <td>not available in demo dataset</td>\n      <td>google</td>\n      <td>1</td>\n      <td>not available in demo dataset</td>\n      <td>1501474532</td>\n      <td>Android</td>\n      <td>Northern America</td>\n      <td>organic</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>Canada</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>Not Socially Engaged</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>not available in demo dataset</td>\n      <td>73.0</td>\n      <td>8</td>\n      <td>not available in demo dataset</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>20170730</td>\n      <td>not available in demo dataset</td>\n      <td>mobile</td>\n      <td>Organic Search</td>\n      <td>not available in demo dataset</td>\n      <td>102</td>\n      <td>not available in demo dataset</td>\n      <td>1501474532</td>\n      <td>Americas</td>\n      <td>True</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>116023 rows × 52 columns</p>\n</div>"},"metadata":{}}],"execution_count":34},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"null_cols = [\n    'totals.visits', 'browserMajor', 'device.browserSize', 'device.screenResolution',\n    'screenSize', 'device.language', 'device.screenColors', 'device.mobileDeviceModel',\n    'device.mobileDeviceBranding', 'device.mobileInputSelector', 'device.mobileDeviceMarketingName',\n    'device.operatingSystemVersion', 'device.flashVersion', 'geoNetwork.networkLocation',\n    'locationZone', 'socialEngagementType', 'device.browserVersion'\n]\nprint(f\"{'Feature':35s}   {'Value':32s} {' Normalized Value'}\")\nfor col in null_cols:\n    vc = df[col].value_counts(normalize=True)\n    if len(vc) == 1:\n        val = vc.index[0]\n        prop = vc.iloc[0]\n        print(f\"{col:35s} -> {str(val):32s} ({prop:.2f})\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:04:23.960025Z","iopub.execute_input":"2025-10-04T14:04:23.960299Z","iopub.status.idle":"2025-10-04T14:04:24.116845Z","shell.execute_reply.started":"2025-10-04T14:04:23.960281Z","shell.execute_reply":"2025-10-04T14:04:24.115672Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Most of these features have only one unique value across the dataset, as shown in the output. These provide no useful variance for model training and can be safely dropped.","metadata":{}},{"cell_type":"code","source":"for col in null_cols:\n    df = df.drop(col, axis=1)\n    dft=dft.drop(col, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:04:36.344562Z","iopub.execute_input":"2025-10-04T14:04:36.344834Z","iopub.status.idle":"2025-10-04T14:04:37.065745Z","shell.execute_reply.started":"2025-10-04T14:04:36.344814Z","shell.execute_reply":"2025-10-04T14:04:37.064851Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Dropping the above-mentioned columns from both training and test sets to clean the dataset and reduce noise.","metadata":{}},{"cell_type":"code","source":"df=df.drop('userId',axis=1)\ndft=dft.drop('userId',axis=1)\ndf=df.drop('sessionId',axis=1)\ndft=dft.drop('sessionId',axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:04:49.803691Z","iopub.execute_input":"2025-10-04T14:04:49.804014Z","iopub.status.idle":"2025-10-04T14:04:49.863638Z","shell.execute_reply.started":"2025-10-04T14:04:49.803991Z","shell.execute_reply":"2025-10-04T14:04:49.862838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Removed userId and sessionId since they are identifiers and don't contribute any meaningful signal to the prediction task.","metadata":{}},{"cell_type":"markdown","source":"# Identifying and Handling Missing Values ","metadata":{}},{"cell_type":"code","source":"null_values=df.isnull().sum()\nnull_values[null_values>0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:05:14.238498Z","iopub.execute_input":"2025-10-04T14:05:14.238858Z","iopub.status.idle":"2025-10-04T14:05:14.366574Z","shell.execute_reply.started":"2025-10-04T14:05:14.238836Z","shell.execute_reply":"2025-10-04T14:05:14.365645Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Removing features with more number of null values (>50%)","metadata":{}},{"cell_type":"code","source":"null_cols=[\n    'trafficSource.adContent',\n    'trafficSource.adwordsClickInfo.slot',\n    'trafficSource.adwordsClickInfo.isVideoAd',\n    'trafficSource.adwordsClickInfo.adNetworkType',\n    'trafficSource.adwordsClickInfo.page'\n]\nfor col in null_cols:\n    df = df.drop(col, axis=1)\n    dft=dft.drop(col, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:05:26.787584Z","iopub.execute_input":"2025-10-04T14:05:26.787910Z","iopub.status.idle":"2025-10-04T14:05:26.907679Z","shell.execute_reply.started":"2025-10-04T14:05:26.787886Z","shell.execute_reply":"2025-10-04T14:05:26.906767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols=['trafficSource.campaign',\n       'trafficSource.keyword',\n       'geoNetwork.metro']\nprint(f\"{'Feature_Name':30s}{'Top Value':30s}\",\"Normalized value\")\nfor col in cols:\n    print(f\"{col:30s}{df[col].value_counts(normalize=True).index[0]:30s}\",df[col].value_counts(normalize=True).iloc[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:05:31.717105Z","iopub.execute_input":"2025-10-04T14:05:31.717418Z","iopub.status.idle":"2025-10-04T14:05:31.777403Z","shell.execute_reply.started":"2025-10-04T14:05:31.717395Z","shell.execute_reply":"2025-10-04T14:05:31.776410Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Since these columns are dominated by a single unknown value, they are not informative. We will remove them.","metadata":{}},{"cell_type":"code","source":"for col in cols:\n    df = df.drop(col, axis=1)\n    dft=dft.drop(col, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:05:44.908892Z","iopub.execute_input":"2025-10-04T14:05:44.909211Z","iopub.status.idle":"2025-10-04T14:05:44.985687Z","shell.execute_reply.started":"2025-10-04T14:05:44.909188Z","shell.execute_reply":"2025-10-04T14:05:44.984667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:05:49.273765Z","iopub.execute_input":"2025-10-04T14:05:49.274071Z","iopub.status.idle":"2025-10-04T14:05:49.369576Z","shell.execute_reply.started":"2025-10-04T14:05:49.274049Z","shell.execute_reply":"2025-10-04T14:05:49.368660Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"These will be handled after train_test_split","metadata":{}},{"cell_type":"markdown","source":"**Feature Engineering** for the 'sessionStart' feature","metadata":{}},{"cell_type":"code","source":"df['sessionStart']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:06:07.488214Z","iopub.execute_input":"2025-10-04T14:06:07.488565Z","iopub.status.idle":"2025-10-04T14:06:07.496746Z","shell.execute_reply.started":"2025-10-04T14:06:07.488539Z","shell.execute_reply":"2025-10-04T14:06:07.495740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['sessionStart_dt'] = pd.to_datetime(df['sessionStart'], unit='s')\ndf['sessionStart_dt']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:06:11.728081Z","iopub.execute_input":"2025-10-04T14:06:11.728381Z","iopub.status.idle":"2025-10-04T14:06:11.750514Z","shell.execute_reply.started":"2025-10-04T14:06:11.728359Z","shell.execute_reply":"2025-10-04T14:06:11.749515Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Converting the session start timestamp to datetime format.","metadata":{}},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"df['hour'] = df['sessionStart_dt'].dt.hour\ndf['dayofweek'] = df['sessionStart_dt'].dt.dayofweek\ndf['month'] = df['sessionStart_dt'].dt.month\ndf.drop(columns=['sessionStart', 'sessionStart_dt'], inplace=True)\n\n#For test df\ndft['sessionStart_dt'] = pd.to_datetime(dft['sessionStart'], unit='s')\ndft['hour'] = dft['sessionStart_dt'].dt.hour\ndft['dayofweek'] = dft['sessionStart_dt'].dt.dayofweek  # 0=Monday\ndft['month'] = dft['sessionStart_dt'].dt.month\ndft.drop(columns=['sessionStart', 'sessionStart_dt'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:06:28.392107Z","iopub.execute_input":"2025-10-04T14:06:28.392410Z","iopub.status.idle":"2025-10-04T14:06:28.452104Z","shell.execute_reply.started":"2025-10-04T14:06:28.392389Z","shell.execute_reply":"2025-10-04T14:06:28.451148Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Select relevant columns\ncols_to_check = ['purchaseValue', 'pageViews', 'totalHits']\ncorr_matrix = df[cols_to_check].corr()\n\n# Display correlation coefficients\nprint(\"Correlation matrix:\\n\", corr_matrix)\n\n# Plot heatmap\nplt.figure(figsize=(6, 4))\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\nplt.title(\"Correlation Heatmap: purchaseValue vs Key Features\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:06:32.299978Z","iopub.execute_input":"2025-10-04T14:06:32.300273Z","iopub.status.idle":"2025-10-04T14:06:33.728025Z","shell.execute_reply.started":"2025-10-04T14:06:32.300242Z","shell.execute_reply":"2025-10-04T14:06:33.726909Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Correlation Analysis with Numerical columns and Target variable","metadata":{}},{"cell_type":"markdown","source":"Target Variable Analysis","metadata":{}},{"cell_type":"code","source":"df['purchaseValue'].value_counts(normalize=True).sort_values(ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:06:48.535504Z","iopub.execute_input":"2025-10-04T14:06:48.536659Z","iopub.status.idle":"2025-10-04T14:06:48.549310Z","shell.execute_reply.started":"2025-10-04T14:06:48.536630Z","shell.execute_reply":"2025-10-04T14:06:48.548334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['purchaseValue'].hist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:06:53.565287Z","iopub.execute_input":"2025-10-04T14:06:53.565622Z","iopub.status.idle":"2025-10-04T14:06:53.798156Z","shell.execute_reply.started":"2025-10-04T14:06:53.565598Z","shell.execute_reply":"2025-10-04T14:06:53.797286Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nnon_zero_values = df[df['purchaseValue'] >0]['purchaseValue']\nplt.figure(figsize=(10, 6))\nsns.kdeplot(non_zero_values, fill=True, color='skyblue', linewidth=2)\nplt.title('Density Plot of Purchase Values (Excluding Zeros)')\nplt.xlabel('Purchase Value')\nplt.ylabel('Density')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:06:58.872557Z","iopub.execute_input":"2025-10-04T14:06:58.872883Z","iopub.status.idle":"2025-10-04T14:06:59.276858Z","shell.execute_reply.started":"2025-10-04T14:06:58.872860Z","shell.execute_reply":"2025-10-04T14:06:59.276020Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can see that most of the values are closer to 0 or even equal to 0, but there are a wide variety of values","metadata":{}},{"cell_type":"code","source":"log_values = np.log1p(df[df['purchaseValue'] > 0]['purchaseValue'])\n\nplt.figure(figsize=(10, 6))\nsns.kdeplot(log_values, fill=True, color='green')\nplt.title('Density Plot of Log-Transformed Purchase Values')\nplt.xlabel('Log(Purchase Value + 1)')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:07:13.633598Z","iopub.execute_input":"2025-10-04T14:07:13.633969Z","iopub.status.idle":"2025-10-04T14:07:14.042856Z","shell.execute_reply.started":"2025-10-04T14:07:13.633946Z","shell.execute_reply":"2025-10-04T14:07:14.041925Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Log Trannsformed Density Plot gives a clear understand of how this plot is actually distributed","metadata":{}},{"cell_type":"markdown","source":"### Insight:\n\nThe target purchaseValue is highly imbalanced with very large values.\n\n~79% of the values are 0.\n\nThe remaining are very high numbers, making this both sparse and skewed.","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Train Test Splitting","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Step 1: Split data\nX = df.drop('purchaseValue', axis=1)\ny = df['purchaseValue']\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:07:44.283994Z","iopub.execute_input":"2025-10-04T14:07:44.284317Z","iopub.status.idle":"2025-10-04T14:07:44.546131Z","shell.execute_reply.started":"2025-10-04T14:07:44.284294Z","shell.execute_reply":"2025-10-04T14:07:44.545188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n\n# Separating High and low Cardinality columns\ncat_cols = X_train.select_dtypes(include='object').columns.tolist()\nlow_card = [col for col in cat_cols if X_train[col].nunique() <= 20]\nhigh_card = [col for col in cat_cols if X_train[col].nunique() > 20]\nnum_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n\nif 'purchaseValue' in num_cols:\n    num_cols.remove('purchaseValue')\n\n#Filling the null values\nfill_values = {}\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        fill_values[col] = X_train[col].mode()[0]\n    else:\n        fill_values[col] = X_train[col].mean()\n\nX_train = X_train.fillna(fill_values)\nX_test = X_test.fillna(fill_values)\n\n# Frequency encode high-card cols\ndef frequency_encode(train, test, cols):\n    for col in cols:\n        freq = train[col].value_counts(normalize=True)\n        train[col] = train[col].map(freq)\n        test[col] = test[col].map(freq).fillna(0)\n    return train, test\n\nX_train, X_test = frequency_encode(X_train, X_test, high_card)\n\n# Column Transformer\npreprocessor = ColumnTransformer([\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False), low_card)\n], remainder='passthrough')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:07:48.551838Z","iopub.execute_input":"2025-10-04T14:07:48.552152Z","iopub.status.idle":"2025-10-04T14:07:49.112336Z","shell.execute_reply.started":"2025-10-04T14:07:48.552130Z","shell.execute_reply":"2025-10-04T14:07:49.111573Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Implementing the Pipeline","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\nimport xgboost as xgb\n\nmodels = {\n    \"Random Forest\": RandomForestRegressor(random_state=42),\n    \"HistGradientBoosting\": HistGradientBoostingRegressor(random_state=42),\n    \"XGBoost\": xgb.XGBRegressor(random_state=42)\n}\n\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nresults=[]\nfor name, model in models.items():\n    pipe = Pipeline([\n        ('preprocessing', preprocessor),\n        ('model', model)\n    ])\n    pipe.fit(X_train, y_train)\n    y_pred = pipe.predict(X_test)\n    r2 = r2_score(y_test, y_pred)\n    mse = mean_squared_error(y_test, y_pred)\n\n    results.append({\n        'Model': name,\n        'R2 Score': round(r2, 4),\n        'MSE': round(mse, 2)\n    })\n\n# Convert to DataFrame\nimport pandas as pd\nresults_df = pd.DataFrame(results)\n\n# Sort by best R2 Score\nresults_df = results_df.sort_values(by='R2 Score', ascending=False)\n\n# Show table\nprint(results_df.to_markdown(index=False)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:07:59.883065Z","iopub.execute_input":"2025-10-04T14:07:59.883341Z","iopub.status.idle":"2025-10-04T14:09:11.531439Z","shell.execute_reply.started":"2025-10-04T14:07:59.883323Z","shell.execute_reply":"2025-10-04T14:09:11.530497Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"When we try a direct Regressor model, we are not getting proper R2 Scores,\n\n### Dual model approach\n\nFirst we do Classification to predict if purchase happened or not and then do Regression to predict the actual purchase value.\n\nClassification – to predict whether a purchase occurs (0 or not)\n\nRegression – to predict the actual purchase amount for non-zero sessions","metadata":{}},{"cell_type":"markdown","source":"### Preprocessing\n\nPreprocessing in such a way to feed to a classifier model","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\ndef full_preprocessing(X_train, X_test, unique_threshold=20):\n    X_train = X_train.copy()\n    X_test = X_test.copy()\n\n    # Handle Missing Values\n    for col in X_train.columns:\n        if X_train[col].dtype == 'object' or X_train[col].dtype.name == 'category':\n            mode_val = X_train[col].mode()[0]\n            X_train[col] = X_train[col].fillna(mode_val)\n            X_test[col] = X_test[col].fillna(mode_val)\n        else:\n            mean_val = X_train[col].mean()\n            X_train[col] = X_train[col].fillna(mean_val)\n            X_test[col] = X_test[col].fillna(mean_val)\n\n    # Identify Categorical Columns\n    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n    low_card_cols = [col for col in categorical_cols if X_train[col].nunique() <= unique_threshold]\n    high_card_cols = [col for col in categorical_cols if X_train[col].nunique() > unique_threshold]\n\n    # Frequency Encoding\n    def frequency_encode(df_train, df_test, columns):\n        for col in columns:\n            freq = df_train[col].value_counts() / len(df_train)\n            df_train[col] = df_train[col].map(freq)\n            df_test[col] = df_test[col].map(freq).fillna(0)\n        return df_train, df_test\n\n    X_train, X_test = frequency_encode(X_train, X_test, high_card_cols)\n\n    numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n    numeric_cols += high_card_cols  # include freq encoded\n\n    # Define Column Transformer\n    preprocessor = ColumnTransformer(transformers=[\n        ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), low_card_cols)\n    ], remainder='passthrough')  # no scaling\n\n    return X_train, X_test, preprocessor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:09:11.533219Z","iopub.execute_input":"2025-10-04T14:09:11.533589Z","iopub.status.idle":"2025-10-04T14:09:11.545191Z","shell.execute_reply.started":"2025-10-04T14:09:11.533566Z","shell.execute_reply":"2025-10-04T14:09:11.544144Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Splitting and applying preprocessing","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop('purchaseValue', axis=1)\ny = df['purchaseValue']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y,random_state=60)\n\nX_train_proc, X_test_proc, preprocessor = full_preprocessing(X_train, X_test)\nX_train_transformed = preprocessor.fit_transform(X_train_proc)\nX_test_transformed = preprocessor.transform(X_test_proc)\n\n#Labels for Classifier\ny_train_class = (y_train > 0).astype(int)\ny_test_class = (y_test > 0).astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:09:11.546064Z","iopub.execute_input":"2025-10-04T14:09:11.546309Z","iopub.status.idle":"2025-10-04T14:09:12.840449Z","shell.execute_reply.started":"2025-10-04T14:09:11.546290Z","shell.execute_reply":"2025-10-04T14:09:12.839623Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training Classifier","metadata":{}},{"cell_type":"markdown","source":"HistGradientBoosting Classifier is the best classifier among all the classifiers I tried","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.metrics import f1_score\n\nclf=HistGradientBoostingClassifier()\nclf.fit(X_train_transformed, y_train_class)\nthreshold = 0.75\nprobs = clf.predict_proba(X_test_transformed)[:, 1]\nstage1_preds = (probs > threshold).astype(int)\nf1_score(y_test_class,stage1_preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:09:12.842193Z","iopub.execute_input":"2025-10-04T14:09:12.842515Z","iopub.status.idle":"2025-10-04T14:09:15.517485Z","shell.execute_reply.started":"2025-10-04T14:09:12.842489Z","shell.execute_reply":"2025-10-04T14:09:15.516693Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Performing Hyper Parameter tuning for HGB Classifier","metadata":{}},{"cell_type":"markdown","source":"Using compute_class_weight library to handle the imbalance in the target var","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.utils.class_weight import compute_class_weight\n\n#Weights for the imbalance\nclass_weights = compute_class_weight('balanced', classes=np.unique(y_train_class), y=y_train_class)\nclass_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n\nparam_grid = {\n    'learning_rate': [0.01, 0.1],\n    'max_iter': [100, 200],\n    'max_depth': [5,7],\n    'l2_regularization': [1.0]\n}\n\nclf_hpt = HistGradientBoostingClassifier(\n    random_state=42,\n    class_weight=class_weight_dict\n)\n\ngrid = GridSearchCV(clf_hpt, param_grid, cv=3, scoring='f1', verbose=1, n_jobs=-1)\ngrid.fit(X_train_transformed, y_train_class)\n\nprint(\"Best params:\", grid.best_params_)\nprint(\"Best F1 score:\", grid.best_score_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:09:48.597249Z","iopub.execute_input":"2025-10-04T14:09:48.597592Z","iopub.status.idle":"2025-10-04T14:10:53.333219Z","shell.execute_reply.started":"2025-10-04T14:09:48.597570Z","shell.execute_reply":"2025-10-04T14:10:53.332543Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we get the best score for the classifier, we train the model with those parameters","metadata":{}},{"cell_type":"code","source":"class_weights = compute_class_weight('balanced', classes=np.unique(y_train_class), y=y_train_class)\nclass_weight_dict = {0: class_weights[0], 1: class_weights[1]}\nclf = HistGradientBoostingClassifier(\n    random_state=42,\n    learning_rate=0.1,\n    max_iter=200,\n    max_depth=7,\n    l2_regularization=1.0,\n    class_weight=class_weight_dict\n)\nclf.fit(X_train_transformed, y_train_class)\n\nthreshold = 0.75\nprobs = clf.predict_proba(X_test_transformed)[:, 1]\nstage1_preds = (probs > threshold).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:10:53.334853Z","iopub.execute_input":"2025-10-04T14:10:53.335106Z","iopub.status.idle":"2025-10-04T14:10:57.838330Z","shell.execute_reply.started":"2025-10-04T14:10:53.335086Z","shell.execute_reply":"2025-10-04T14:10:57.837675Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Coming to Regression of those predicted values\n\nWe do Random Forest Regressor - which overall was the best regressor (in this dual model pipeline) when I tried with other models","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\n\n# Higher weight for positive purchases\nweights = np.where(y_train > 0, 20, 1)\n\nregressor = RandomForestRegressor(random_state=42)\nregressor.fit(X_train_transformed, y_train,sample_weight=weights)\n\n# Predict only for predicted positive sessions\nregression_preds = regressor.predict(X_test_transformed[stage1_preds == 1])\n\n# Merge predictions\nfinal_preds = np.zeros(len(X_test_transformed))\nfinal_preds[stage1_preds == 1] = regression_preds\n\n# Evaluate\nprint(\"Final R2 Score:\", r2_score(y_test, final_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:10:57.839773Z","iopub.execute_input":"2025-10-04T14:10:57.840109Z","iopub.status.idle":"2025-10-04T14:11:59.363986Z","shell.execute_reply.started":"2025-10-04T14:10:57.840085Z","shell.execute_reply":"2025-10-04T14:11:59.363116Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Performing HyperParameter Tuning for Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# Filter only positive purchase sessions for training\nmask_train = y_train > 0\nX_train_pos = X_train_transformed[mask_train]\ny_train_pos = y_train[mask_train]\nweights_pos = np.where(y_train_pos > 0, 20, 1)  # same logic\n\n# Grid Search params\nparam_grid = {\n    'n_estimators': [100, 200],\n    'max_depth': [10, 15],\n    'min_samples_split': [2, 5],\n}\n\nreg = RandomForestRegressor(random_state=42)\n\ngrid = GridSearchCV(\n    estimator=reg,\n    param_grid=param_grid,\n    cv=2,\n    scoring='r2',\n    verbose=1,\n    n_jobs=-1\n)\n\ngrid.fit(X_train_pos, y_train_pos, sample_weight=weights_pos)\n\nbest_rf = grid.best_estimator_\n\n# Predict only for predicted positive sessions in test\nregression_preds = best_rf.predict(X_test_transformed[stage1_preds == 1])\n\n# Merge predictions\nfinal_preds = np.zeros(len(X_test_transformed))\nfinal_preds[stage1_preds == 1] = regression_preds\n\n# Evaluate\nfrom sklearn.metrics import r2_score\nprint(\"Final R2 Score on Full Test Set:\", r2_score(y_test, final_preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:11:59.365865Z","iopub.execute_input":"2025-10-04T14:11:59.366111Z","iopub.status.idle":"2025-10-04T14:13:08.257252Z","shell.execute_reply.started":"2025-10-04T14:11:59.366094Z","shell.execute_reply":"2025-10-04T14:13:08.256283Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can notice there is poor performance when we do hyper parameter tuning for random forest, so we just pass the actual model with all default hyper parameters (as before) for better performance","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\n\n# Higher weight for positive purchases\nweights = np.where(y_train > 0, 20, 1)\n\nregressor = RandomForestRegressor(random_state=42)\nregressor.fit(X_train_transformed, y_train,sample_weight=weights)\n\n# Predict only for predicted positive sessions\nregression_preds = regressor.predict(X_test_transformed[stage1_preds == 1])\n\n# Merge predictions\nfinal_preds = np.zeros(len(X_test_transformed))\nfinal_preds[stage1_preds == 1] = regression_preds\n\n# Evaluate\nprint(\"Final R2 Score:\", r2_score(y_test, final_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:13:08.258166Z","iopub.execute_input":"2025-10-04T14:13:08.258429Z","iopub.status.idle":"2025-10-04T14:14:12.989302Z","shell.execute_reply.started":"2025-10-04T14:13:08.258408Z","shell.execute_reply":"2025-10-04T14:14:12.988436Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The Final R2 Score with all default hyper parameters in random forest model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\n# Train R² (regression only on y_train > 0)\ntrain_mask = y_train > 0\nreg_train_preds = regressor.predict(X_train_transformed[train_mask])\ntrain_r2 = r2_score(y_train[train_mask], reg_train_preds)\nprint(\"Train R²:\", train_r2)\n\n# Test R²\ntest_mask = stage1_preds == 1\nreg_test_preds = regressor.predict(X_test_transformed[test_mask])\ntest_r2 = r2_score(y_test[test_mask], reg_test_preds)\nprint(\"Test R²:\", test_r2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:14:12.990153Z","iopub.execute_input":"2025-10-04T14:14:12.990366Z","iopub.status.idle":"2025-10-04T14:14:13.850961Z","shell.execute_reply.started":"2025-10-04T14:14:12.990348Z","shell.execute_reply":"2025-10-04T14:14:13.850221Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This is the highest R2 for both train adn test I got, which explains least overfitting of the model\n\nOther different models gave better training score but very low testing score, so that lead to overfitting of the model.","metadata":{}},{"cell_type":"code","source":"X_dft = dft.copy()\n\n_, X_dft_proc, _ = full_preprocessing(X_train.copy(), X_dft.copy(), unique_threshold=20)\n\nX_dft_transformed = preprocessor.transform(X_dft_proc)\n\nprobs_dft = clf.predict_proba(X_dft_transformed)[:, 1]\nstage1_preds = (probs_dft > threshold).astype(int)\n\nregression_preds = regressor.predict(X_dft_transformed[stage1_preds == 1])\n\nfinal_preds = np.zeros(len(X_dft_transformed))\nfinal_preds[stage1_preds == 1] = regression_preds\n\nsubmission = pd.DataFrame({\n    'id': range(len(final_preds)),\n    'purchaseValue': final_preds\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"✅ submission.csv created successfully.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-04T14:14:13.851822Z","iopub.execute_input":"2025-10-04T14:14:13.852066Z","iopub.status.idle":"2025-10-04T14:14:15.103304Z","shell.execute_reply.started":"2025-10-04T14:14:13.852047Z","shell.execute_reply":"2025-10-04T14:14:15.102489Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This is the final submission file for the test dataset given for the competition.\n\nPreprocessing dft (test df) and applying these models, and predicting the values for final submission.csv file","metadata":{}}]}